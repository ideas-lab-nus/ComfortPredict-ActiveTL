{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries and model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 23:28:37.144880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "random.seed(1)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Define model hyperparameters\n",
    "parser = argparse.ArgumentParser(description='TL-CNN-LSTM Feature Extraction Model')\n",
    "parser.add_argument('--input_size', type=int, default=7)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.000001)\n",
    "parser.add_argument('--input_features', type=list, default=['Mode',\n",
    "                                                            'Indoor Temp',\n",
    "                                                            'Indoor Humidity',\n",
    "                                                            'Air Velocity',\n",
    "                                                            'Globe Temperature',\n",
    "                                                            'Outdoor Temp',\n",
    "                                                            'Outdoor Humidity'])\n",
    "parser.add_argument('--experiment', type=str, default='mode_al') \n",
    "# choose either 'condition_random', 'mode_random', 'mode_al', 'all'\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "mode_mapping = {'AC':0, 'NV':1}\n",
    "thermalpref_mapping = {'No Change':0, 'Warmer':1, 'Cooler':2}\n",
    "thermalacc_mapping = {'Acceptable':0, 'Unacceptable':1}\n",
    "airpref_mapping = {'No Change':0, 'More':1, 'Less':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load training data from ASHRAE dataset\n",
    "ashrae_thermalpref_train = pd.read_csv('../data/ashrae_thermalpref_sampled_data.csv')\n",
    "ashrae_thermalacc_train = pd.read_csv('../data/ashrae_thermalacc_sampled_data.csv')\n",
    "ashrae_airpref_train = pd.read_csv('../data/ashrae_airpref_sampled_data.csv')\n",
    "\n",
    "# load training data from BCA dataset\n",
    "if args.experiment == 'condition_random':\n",
    "    bca_thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_condition_random_data.csv')\n",
    "    bca_thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_condition_random_data.csv')\n",
    "    bca_airpref_train = pd.read_csv('../data/bca_airpref_train_condition_random_data.csv')\n",
    "elif args.experiment == 'mode_random':\n",
    "    bca_thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_random_data.csv')\n",
    "    bca_thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_random_data.csv')\n",
    "    bca_airpref_train = pd.read_csv('../data/bca_airpref_train_mode_random_data.csv')\n",
    "elif args.experiment == 'mode_al':\n",
    "    bca_thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_mode_al_data.csv')\n",
    "    bca_thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_mode_al_data.csv')\n",
    "    bca_airpref_train = pd.read_csv('../data/bca_airpref_train_mode_al_data.csv')\n",
    "elif args.experiment == 'all':\n",
    "    bca_thermalpref_train = pd.read_csv('../data/bca_thermalpref_train_data.csv')\n",
    "    bca_thermalacc_train = pd.read_csv('../data/bca_thermalacc_train_data.csv')\n",
    "    bca_airpref_train = pd.read_csv('../data/bca_airpref_train_data.csv') \n",
    "else:\n",
    "    raise ValueError(f\"Experiment {args.experiment} is not supported.\")\n",
    "\n",
    "# load test data from BCA dataset\n",
    "bca_thermalpref_test = pd.read_csv('../data/bca_thermalpref_test_data.csv')\n",
    "bca_thermalacc_test = pd.read_csv('../data/bca_thermalacc_test_data.csv')\n",
    "bca_airpref_test = pd.read_csv('../data/bca_airpref_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# perform one hot encoding\n",
    "ashrae_thermalpref_train['Mode'] = ashrae_thermalpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_thermalpref_train['Mode'] = bca_thermalpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_thermalpref_test['Mode'] = bca_thermalpref_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "ashrae_thermalacc_train['Mode'] = ashrae_thermalacc_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_thermalacc_train['Mode'] = bca_thermalacc_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_thermalacc_test['Mode'] = bca_thermalacc_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "ashrae_airpref_train['Mode'] = ashrae_airpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_airpref_train['Mode'] = bca_airpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "bca_airpref_test['Mode'] = bca_airpref_test['Mode'].apply(lambda x: mode_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform label mapping\n",
    "ashrae_thermalpref_train['Thermal Preference'] = ashrae_thermalpref_train['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "bca_thermalpref_train['Thermal Preference'] = bca_thermalpref_train['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "bca_thermalpref_test['Thermal Preference'] = bca_thermalpref_test['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "\n",
    "ashrae_thermalacc_train['Thermal Acceptability'] = ashrae_thermalacc_train['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "bca_thermalacc_train['Thermal Acceptability'] = bca_thermalacc_train['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "bca_thermalacc_test['Thermal Acceptability'] = bca_thermalacc_test['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "\n",
    "ashrae_airpref_train['Air Movement Preference'] = ashrae_airpref_train['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "bca_airpref_train['Air Movement Preference'] = bca_airpref_train['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "bca_airpref_test['Air Movement Preference'] = bca_airpref_test['Air Movement Preference'].apply(lambda x: airpref_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_pretrained_model(model_name):\n",
    "    \"\"\"\n",
    "    Loads the CNN LSTM model that was pretrained on the ASHRAE dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        model_name: The name of the CNN LSTM model pretrained on the ASHRAE dataset.\n",
    "        \n",
    "    Return:\n",
    "        model: The CNN LSTM model pretrained on the ASHRAE dataset.\n",
    "    \"\"\"\n",
    "    # Load the pre-trained CNN LSTM model\n",
    "    pretrained_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "\n",
    "    # Freeze feature extraction layers (CNN + LSTM)\n",
    "    for layer in pretrained_model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Print model summary\n",
    "    print(pretrained_model.summary())\n",
    "    \n",
    "    return pretrained_model\n",
    "\n",
    "def generate_ashrae_scaler(ashrae_data, target_col):\n",
    "    \"\"\"\n",
    "    Generates a feature scaler based on the ASHRAE dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        ashrae_data: The ASHRAE dataset that the model is pretrained on.\n",
    "        target_col: The target column in the ASHRAE dataset.\n",
    "        \n",
    "    Returns:\n",
    "        scaler: The MinMax scaler fitted on the ASHRAE dataset.\n",
    "    \"\"\"\n",
    "    X = np.array(ashrae_data[args.input_features])\n",
    "    y = np.array(ashrae_data[target_col])\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Create and fit a Min-Max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    return scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_df, scaler, model_name, target_col, num_classes):\n",
    "    # Assuming train_df has columns for features and a 'target' column for labels\n",
    "    X = np.array(train_df[args.input_features])\n",
    "    y = np.array(train_df[target_col])\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Create and fit a Min-Max scaler\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',  # Monitor validation loss\n",
    "        patience=10,          # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True  # Restore the best model weights when training stops\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_scaled, \n",
    "                        y_train, \n",
    "                        epochs=args.num_epochs, \n",
    "                        batch_size=args.batch_size,\n",
    "                        validation_data=(X_val_scaled, y_val), \n",
    "                        callbacks=[checkpoint_callback, early_stopping_callback])\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "    print(history)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_df, scaler, model_name, target_col, metrics=['accuracy', 'weighted_f1']):\n",
    "    # Assuming test_df has columns for features and a 'target' column for labels\n",
    "    X_test = np.array(test_df[args.input_features])\n",
    "    y_true = np.array(test_df[target_col])\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    loaded_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "    \n",
    "    # Apply numerical scaler on X_test\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    y_pred = loaded_model.predict(X_test_scaled)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    if 'accuracy' in metrics:\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        evaluation_results['accuracy'] = accuracy\n",
    "\n",
    "    if 'weighted_f1' in metrics:\n",
    "        weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "        evaluation_results['weighted_f1'] = weighted_f1\n",
    "\n",
    "    return evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Preference Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 23:28:40.526755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 920,320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 662ms/step - loss: 1.5543 - accuracy: 0.4835 - val_loss: 1.0623 - val_accuracy: 0.5217\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.0688 - accuracy: 0.5055 - val_loss: 0.9426 - val_accuracy: 0.4348\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.8712 - accuracy: 0.5165 - val_loss: 0.8999 - val_accuracy: 0.4348\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.8296 - accuracy: 0.5495 - val_loss: 0.9221 - val_accuracy: 0.4348\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.7785 - accuracy: 0.5495 - val_loss: 0.9003 - val_accuracy: 0.4783\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.7613 - accuracy: 0.5495 - val_loss: 0.8897 - val_accuracy: 0.4783\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.7537 - accuracy: 0.5934 - val_loss: 0.8852 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.7603 - accuracy: 0.6044 - val_loss: 0.8687 - val_accuracy: 0.4348\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.7428 - accuracy: 0.6264 - val_loss: 0.8495 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.7127 - accuracy: 0.6703 - val_loss: 0.8425 - val_accuracy: 0.4783\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.7038 - accuracy: 0.6264 - val_loss: 0.8444 - val_accuracy: 0.4783\n",
      "<keras.callbacks.History object at 0x7feb9c20ae80>\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Thermal Preference Accuracy: 0.5631578947368421\n",
      "Thermal Preference Weighted F1 Score: 0.5130833782924783\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Preference Model\")\n",
    "thermalpref_model = load_pretrained_model('cnnlstm_lower_thermalpref_model')\n",
    "thermalpref_scaler = generate_ashrae_scaler(ashrae_thermalpref_train, \n",
    "                                            target_col='Thermal Preference')\n",
    "thermalpref_model = train_model(thermalpref_model, \n",
    "                                bca_thermalpref_train, \n",
    "                                thermalpref_scaler,\n",
    "                                model_name='tl_cnnlstm_fe_thermalpref_model', \n",
    "                                target_col='Thermal Preference', \n",
    "                                num_classes=3)\n",
    "thermalpref_eval = evaluate_model(thermalpref_model, \n",
    "                                  bca_thermalpref_test, \n",
    "                                  thermalpref_scaler,\n",
    "                                  model_name='tl_cnnlstm_fe_thermalpref_model', \n",
    "                                  target_col='Thermal Preference')\n",
    "print(\"Thermal Preference Accuracy:\", thermalpref_eval['accuracy'])\n",
    "print(\"Thermal Preference Weighted F1 Score:\", thermalpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Acceptability Model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,842\n",
      "Trainable params: 17,522\n",
      "Non-trainable params: 920,320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 684ms/step - loss: 1.9655 - accuracy: 0.2857 - val_loss: 0.9869 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.8045 - accuracy: 0.5275 - val_loss: 0.8288 - val_accuracy: 0.6087\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6081 - accuracy: 0.7253 - val_loss: 0.7301 - val_accuracy: 0.6522\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5018 - accuracy: 0.8022 - val_loss: 0.6363 - val_accuracy: 0.6522\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4037 - accuracy: 0.8242 - val_loss: 0.6450 - val_accuracy: 0.6087\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.3667 - accuracy: 0.8022 - val_loss: 0.6817 - val_accuracy: 0.7391\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3797 - accuracy: 0.8242 - val_loss: 0.8440 - val_accuracy: 0.7826\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3481 - accuracy: 0.8022 - val_loss: 0.9377 - val_accuracy: 0.6957\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3239 - accuracy: 0.8022 - val_loss: 0.9397 - val_accuracy: 0.7391\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3772 - accuracy: 0.8132 - val_loss: 0.8152 - val_accuracy: 0.6522\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3703 - accuracy: 0.8022 - val_loss: 0.7995 - val_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3543 - accuracy: 0.8462 - val_loss: 0.8618 - val_accuracy: 0.6522\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3382 - accuracy: 0.8132 - val_loss: 0.9651 - val_accuracy: 0.6522\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3062 - accuracy: 0.8352 - val_loss: 1.0648 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3232 - accuracy: 0.8132 - val_loss: 1.0604 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.2986 - accuracy: 0.8132 - val_loss: 1.0215 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2978 - accuracy: 0.8242 - val_loss: 1.0174 - val_accuracy: 0.6957\n",
      "<keras.callbacks.History object at 0x7feb9ccdb0a0>\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Thermal Acceptability Accuracy: 0.8263157894736842\n",
      "Thermal Acceptability Weighted F1 Score: 0.7914634592035216\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal acceptability model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Acceptability Model\")\n",
    "thermalacc_model = load_pretrained_model('cnnlstm_lower_thermalacc_model')\n",
    "thermalacc_scaler = generate_ashrae_scaler(ashrae_thermalacc_train, \n",
    "                                           target_col='Thermal Acceptability')\n",
    "thermalacc_model = train_model(thermalacc_model, \n",
    "                               bca_thermalacc_train, \n",
    "                               thermalacc_scaler,\n",
    "                               model_name='tl_cnnlstm_fe_thermalacc_model', \n",
    "                               target_col='Thermal Acceptability', \n",
    "                               num_classes=2)\n",
    "thermalacc_eval = evaluate_model(thermalacc_model, \n",
    "                                  bca_thermalacc_test, \n",
    "                                  thermalacc_scaler,\n",
    "                                  model_name='tl_cnnlstm_fe_thermalacc_model', \n",
    "                                  target_col='Thermal Acceptability')\n",
    "print(\"Thermal Acceptability Accuracy:\", thermalacc_eval['accuracy'])\n",
    "print(\"Thermal Acceptability Weighted F1 Score:\", thermalacc_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Air Movement Preference Model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 920,320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 611ms/step - loss: 0.9680 - accuracy: 0.5055 - val_loss: 0.9040 - val_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7914 - accuracy: 0.6593 - val_loss: 1.0301 - val_accuracy: 0.3913\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.7115 - accuracy: 0.6813 - val_loss: 1.1753 - val_accuracy: 0.4348\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7192 - accuracy: 0.6593 - val_loss: 1.1546 - val_accuracy: 0.3913\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.7141 - accuracy: 0.6593 - val_loss: 1.2072 - val_accuracy: 0.3478\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.7277 - accuracy: 0.6264 - val_loss: 1.2506 - val_accuracy: 0.4348\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6763 - accuracy: 0.6593 - val_loss: 1.2930 - val_accuracy: 0.4348\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6680 - accuracy: 0.7033 - val_loss: 1.3330 - val_accuracy: 0.3913\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6759 - accuracy: 0.6813 - val_loss: 1.3556 - val_accuracy: 0.4783\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6584 - accuracy: 0.6593 - val_loss: 1.3272 - val_accuracy: 0.4348\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6428 - accuracy: 0.6593 - val_loss: 1.3727 - val_accuracy: 0.4783\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6049 - accuracy: 0.7033 - val_loss: 1.3593 - val_accuracy: 0.4783\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6172 - accuracy: 0.6813 - val_loss: 1.3025 - val_accuracy: 0.4783\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5724 - accuracy: 0.7582 - val_loss: 1.2841 - val_accuracy: 0.5217\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5974 - accuracy: 0.6703 - val_loss: 1.3724 - val_accuracy: 0.4783\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6018 - accuracy: 0.7033 - val_loss: 1.4082 - val_accuracy: 0.5652\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5398 - accuracy: 0.7143 - val_loss: 1.4277 - val_accuracy: 0.4348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6382 - accuracy: 0.6923 - val_loss: 1.3935 - val_accuracy: 0.4348\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5554 - accuracy: 0.7253 - val_loss: 1.4326 - val_accuracy: 0.4348\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5986 - accuracy: 0.7253 - val_loss: 1.4053 - val_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5622 - accuracy: 0.6923 - val_loss: 1.4311 - val_accuracy: 0.5217\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5506 - accuracy: 0.7033 - val_loss: 1.5314 - val_accuracy: 0.4783\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5360 - accuracy: 0.7473 - val_loss: 1.5652 - val_accuracy: 0.4783\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4994 - accuracy: 0.7253 - val_loss: 1.5838 - val_accuracy: 0.5217\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5373 - accuracy: 0.7143 - val_loss: 1.5406 - val_accuracy: 0.4783\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5530 - accuracy: 0.7033 - val_loss: 1.4737 - val_accuracy: 0.4348\n",
      "<keras.callbacks.History object at 0x7feb8bbb0160>\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Air Movement Preference Accuracy: 0.5842105263157895\n",
      "Air Movement Preference Weighted F1 Score: 0.5475262118613919\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate air movement preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Air Movement Preference Model\")\n",
    "airpref_model = load_pretrained_model('cnnlstm_lower_airpref_model')\n",
    "airpref_scaler = generate_ashrae_scaler(ashrae_airpref_train, \n",
    "                                        target_col='Air Movement Preference')\n",
    "airpref_model = train_model(airpref_model, \n",
    "                            bca_airpref_train, \n",
    "                            airpref_scaler,\n",
    "                            model_name='tl_cnnlstm_fe_airpref_model', \n",
    "                            target_col='Air Movement Preference',\n",
    "                            num_classes=3)\n",
    "airpref_eval = evaluate_model(airpref_model, \n",
    "                              bca_airpref_test, \n",
    "                              airpref_scaler,\n",
    "                              model_name='tl_cnnlstm_fe_airpref_model', \n",
    "                              target_col='Air Movement Preference')\n",
    "print(\"Air Movement Preference Accuracy:\", airpref_eval['accuracy'])\n",
    "print(\"Air Movement Preference Weighted F1 Score:\", airpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}