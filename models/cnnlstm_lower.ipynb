{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries and model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 19:06:18.889405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "random.seed(1)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Define model hyperparameters\n",
    "parser = argparse.ArgumentParser(description='CNN-LSTM Lower Bound')\n",
    "parser.add_argument('--input_size', type=int, default=7)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--num_epochs', type=int, default=100)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "parser.add_argument('--input_features', type=list, default=['Mode',\n",
    "                                                            'Indoor Temp',\n",
    "                                                            'Indoor Humidity',\n",
    "                                                            'Air Velocity',\n",
    "                                                            'Globe Temperature',\n",
    "                                                            'Outdoor Temp',\n",
    "                                                            'Outdoor Humidity'])\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "mode_mapping = {'AC':0, 'NV':1}\n",
    "thermalpref_mapping = {'No Change':0, 'Warmer':1, 'Cooler':2}\n",
    "thermalacc_mapping = {'Acceptable':0, 'Unacceptable':1}\n",
    "airpref_mapping = {'No Change':0, 'More':1, 'Less':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load training data from ASHRAE dataset\n",
    "thermalpref_train = pd.read_csv('../data/ashrae_thermalpref_sampled_data.csv')\n",
    "thermalacc_train = pd.read_csv('../data/ashrae_thermalacc_sampled_data.csv')\n",
    "airpref_train = pd.read_csv('../data/ashrae_airpref_sampled_data.csv')\n",
    "\n",
    "# load test data from BCA dataset\n",
    "thermalpref_test = pd.read_csv('../data/bca_thermalpref_test_data.csv')\n",
    "thermalacc_test = pd.read_csv('../data/bca_thermalacc_test_data.csv')\n",
    "airpref_test = pd.read_csv('../data/bca_airpref_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# perform one hot encoding\n",
    "thermalpref_train['Mode'] = thermalpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "thermalpref_test['Mode'] = thermalpref_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "thermalacc_train['Mode'] = thermalacc_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "thermalacc_test['Mode'] = thermalacc_test['Mode'].apply(lambda x: mode_mapping[x])\n",
    "\n",
    "airpref_train['Mode'] = airpref_train['Mode'].apply(lambda x: mode_mapping[x])\n",
    "airpref_test['Mode'] = airpref_test['Mode'].apply(lambda x: mode_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform label mapping\n",
    "thermalpref_train['Thermal Preference'] = thermalpref_train['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "thermalpref_test['Thermal Preference'] = thermalpref_test['Thermal Preference'].apply(lambda x: thermalpref_mapping[x])\n",
    "\n",
    "thermalacc_train['Thermal Acceptability'] = thermalacc_train['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "thermalacc_test['Thermal Acceptability'] = thermalacc_test['Thermal Acceptability'].apply(lambda x: thermalacc_mapping[x])\n",
    "\n",
    "airpref_train['Air Movement Preference'] = airpref_train['Air Movement Preference'].apply(lambda x: airpref_mapping[x])\n",
    "airpref_test['Air Movement Preference'] = airpref_test['Air Movement Preference'].apply(lambda x: airpref_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_model_architecture(num_classes):\n",
    "    \"\"\"\n",
    "    Defines the CNN LSTM model architecture with model parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        num_classes: An integer value indicating the number of output classes for the model.\n",
    "        \n",
    "    Return:\n",
    "        model: The Keras object containing the CNN LSTM model architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Convolutional Layer (Part of the model to be retrained)\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, padding='same', input_shape=(args.input_size, 1), trainable=True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Two LSTM Layers (Part of the model to be retrained)\n",
    "    model.add(LSTM(256, return_sequences=True, recurrent_dropout=0.1, trainable=True))\n",
    "    model.add(LSTM(256, return_sequences=False, recurrent_dropout=0.1, trainable=True))\n",
    "\n",
    "    # Flatten the output from LSTM layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Two Dense (Fully Connected) Layers (These layers will remain fixed)\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='glorot_uniform', trainable=True))\n",
    "\n",
    "    # Output Layer (Part of the model to be retrained)\n",
    "    model.add(Dense(num_classes, activation='softmax', trainable=True))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_df, model_name, target_col, num_classes):\n",
    "    # Assuming train_df has columns for features and a 'target' column for labels\n",
    "    X = np.array(train_df[args.input_features])\n",
    "    y = np.array(train_df[target_col])\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Create and fit a Min-Max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "    # Define a callback to save the best model during training\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',  # Monitor validation loss\n",
    "        patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "        restore_best_weights=True  # Restore the best model weights when training stops\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_scaled, \n",
    "                        y_train, \n",
    "                        epochs=args.num_epochs, \n",
    "                        batch_size=args.batch_size,\n",
    "                        validation_data=(X_val_scaled, y_val), \n",
    "                        callbacks=[checkpoint_callback])\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "    print(history)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "def evaluate_model(model, test_df, scaler, model_name, target_col, metrics=['accuracy', 'weighted_f1']):\n",
    "    # Assuming test_df has columns for features and a 'target' column for labels\n",
    "    X_test = np.array(test_df[args.input_features])\n",
    "    y_true = np.array(test_df[target_col])\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    loaded_model = tf.keras.models.load_model(model_name + '.h5')\n",
    "    \n",
    "    # Apply numerical scaler on X_test\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    y_pred = loaded_model.predict(X_test_scaled)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    evaluation_results = {}\n",
    "\n",
    "    if 'accuracy' in metrics:\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        evaluation_results['accuracy'] = accuracy\n",
    "\n",
    "    if 'weighted_f1' in metrics:\n",
    "        weighted_f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "        evaluation_results['weighted_f1'] = weighted_f1\n",
    "\n",
    "    return evaluation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Preference Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 19:06:23.430100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "633/633 [==============================] - 56s 83ms/step - loss: 0.9722 - accuracy: 0.4991 - val_loss: 0.9503 - val_accuracy: 0.5220\n",
      "Epoch 2/100\n",
      "633/633 [==============================] - 73s 115ms/step - loss: 0.9496 - accuracy: 0.5202 - val_loss: 0.9391 - val_accuracy: 0.5296\n",
      "Epoch 3/100\n",
      "633/633 [==============================] - 73s 115ms/step - loss: 0.9453 - accuracy: 0.5240 - val_loss: 0.9407 - val_accuracy: 0.5341\n",
      "Epoch 4/100\n",
      "633/633 [==============================] - 94s 149ms/step - loss: 0.9435 - accuracy: 0.5250 - val_loss: 0.9437 - val_accuracy: 0.5343\n",
      "Epoch 5/100\n",
      "633/633 [==============================] - 99s 156ms/step - loss: 0.9399 - accuracy: 0.5284 - val_loss: 0.9420 - val_accuracy: 0.5311\n",
      "Epoch 6/100\n",
      "633/633 [==============================] - 89s 141ms/step - loss: 0.9389 - accuracy: 0.5295 - val_loss: 0.9398 - val_accuracy: 0.5283\n",
      "Epoch 7/100\n",
      "633/633 [==============================] - 62s 98ms/step - loss: 0.9349 - accuracy: 0.5336 - val_loss: 0.9324 - val_accuracy: 0.5419\n",
      "Epoch 8/100\n",
      "633/633 [==============================] - 57s 90ms/step - loss: 0.9326 - accuracy: 0.5347 - val_loss: 0.9271 - val_accuracy: 0.5403\n",
      "Epoch 9/100\n",
      "633/633 [==============================] - 2469s 4s/step - loss: 0.9292 - accuracy: 0.5371 - val_loss: 0.9279 - val_accuracy: 0.5377\n",
      "Epoch 10/100\n",
      "633/633 [==============================] - 53s 84ms/step - loss: 0.9277 - accuracy: 0.5380 - val_loss: 0.9230 - val_accuracy: 0.5419\n",
      "Epoch 11/100\n",
      "633/633 [==============================] - 46s 73ms/step - loss: 0.9248 - accuracy: 0.5393 - val_loss: 0.9240 - val_accuracy: 0.5428\n",
      "Epoch 12/100\n",
      "633/633 [==============================] - 49s 77ms/step - loss: 0.9225 - accuracy: 0.5419 - val_loss: 0.9183 - val_accuracy: 0.5453\n",
      "Epoch 13/100\n",
      "633/633 [==============================] - 55s 86ms/step - loss: 0.9198 - accuracy: 0.5430 - val_loss: 0.9175 - val_accuracy: 0.5484\n",
      "Epoch 14/100\n",
      "633/633 [==============================] - 51s 81ms/step - loss: 0.9187 - accuracy: 0.5443 - val_loss: 0.9154 - val_accuracy: 0.5464\n",
      "Epoch 15/100\n",
      "633/633 [==============================] - 44s 69ms/step - loss: 0.9165 - accuracy: 0.5465 - val_loss: 0.9145 - val_accuracy: 0.5464\n",
      "Epoch 16/100\n",
      "633/633 [==============================] - 388s 614ms/step - loss: 0.9142 - accuracy: 0.5470 - val_loss: 0.9139 - val_accuracy: 0.5506\n",
      "Epoch 17/100\n",
      "633/633 [==============================] - 47s 74ms/step - loss: 0.9127 - accuracy: 0.5469 - val_loss: 0.9106 - val_accuracy: 0.5504\n",
      "Epoch 18/100\n",
      "633/633 [==============================] - 45s 72ms/step - loss: 0.9100 - accuracy: 0.5496 - val_loss: 0.9083 - val_accuracy: 0.5510\n",
      "Epoch 19/100\n",
      "633/633 [==============================] - 46s 73ms/step - loss: 0.9077 - accuracy: 0.5521 - val_loss: 0.9072 - val_accuracy: 0.5509\n",
      "Epoch 20/100\n",
      "633/633 [==============================] - 44s 69ms/step - loss: 0.9048 - accuracy: 0.5538 - val_loss: 0.9053 - val_accuracy: 0.5544\n",
      "Epoch 21/100\n",
      "633/633 [==============================] - 43s 69ms/step - loss: 0.9031 - accuracy: 0.5539 - val_loss: 0.9009 - val_accuracy: 0.5543\n",
      "Epoch 22/100\n",
      "633/633 [==============================] - 43s 69ms/step - loss: 0.8999 - accuracy: 0.5557 - val_loss: 0.9016 - val_accuracy: 0.5584\n",
      "Epoch 23/100\n",
      "633/633 [==============================] - 44s 70ms/step - loss: 0.8972 - accuracy: 0.5603 - val_loss: 0.9029 - val_accuracy: 0.5565\n",
      "Epoch 24/100\n",
      "633/633 [==============================] - 44s 70ms/step - loss: 0.8950 - accuracy: 0.5594 - val_loss: 0.8994 - val_accuracy: 0.5537\n",
      "Epoch 25/100\n",
      "633/633 [==============================] - 44s 70ms/step - loss: 0.8925 - accuracy: 0.5620 - val_loss: 0.8920 - val_accuracy: 0.5640\n",
      "Epoch 26/100\n",
      "633/633 [==============================] - 46s 73ms/step - loss: 0.8883 - accuracy: 0.5650 - val_loss: 0.9003 - val_accuracy: 0.5608\n",
      "Epoch 27/100\n",
      "633/633 [==============================] - 48s 76ms/step - loss: 0.8857 - accuracy: 0.5652 - val_loss: 0.8924 - val_accuracy: 0.5652\n",
      "Epoch 28/100\n",
      "633/633 [==============================] - 48s 76ms/step - loss: 0.8837 - accuracy: 0.5670 - val_loss: 0.8989 - val_accuracy: 0.5616\n",
      "Epoch 29/100\n",
      "633/633 [==============================] - 50s 79ms/step - loss: 0.8804 - accuracy: 0.5696 - val_loss: 0.8854 - val_accuracy: 0.5648\n",
      "Epoch 30/100\n",
      "633/633 [==============================] - 50s 80ms/step - loss: 0.8756 - accuracy: 0.5723 - val_loss: 0.8978 - val_accuracy: 0.5572\n",
      "Epoch 31/100\n",
      "633/633 [==============================] - 51s 80ms/step - loss: 0.8720 - accuracy: 0.5749 - val_loss: 0.8822 - val_accuracy: 0.5698\n",
      "Epoch 32/100\n",
      "633/633 [==============================] - 52s 82ms/step - loss: 0.8693 - accuracy: 0.5755 - val_loss: 0.8856 - val_accuracy: 0.5674\n",
      "Epoch 33/100\n",
      "633/633 [==============================] - 53s 84ms/step - loss: 0.8647 - accuracy: 0.5810 - val_loss: 0.8799 - val_accuracy: 0.5728\n",
      "Epoch 34/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.8617 - accuracy: 0.5810 - val_loss: 0.8810 - val_accuracy: 0.5730\n",
      "Epoch 35/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.8588 - accuracy: 0.5834 - val_loss: 0.8871 - val_accuracy: 0.5652\n",
      "Epoch 36/100\n",
      "633/633 [==============================] - 55s 87ms/step - loss: 0.8540 - accuracy: 0.5867 - val_loss: 0.8735 - val_accuracy: 0.5767\n",
      "Epoch 37/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.8497 - accuracy: 0.5883 - val_loss: 0.8776 - val_accuracy: 0.5737\n",
      "Epoch 38/100\n",
      "633/633 [==============================] - 56s 89ms/step - loss: 0.8475 - accuracy: 0.5904 - val_loss: 0.8723 - val_accuracy: 0.5785\n",
      "Epoch 39/100\n",
      "633/633 [==============================] - 56s 89ms/step - loss: 0.8422 - accuracy: 0.5918 - val_loss: 0.8703 - val_accuracy: 0.5765\n",
      "Epoch 40/100\n",
      "633/633 [==============================] - 59s 92ms/step - loss: 0.8375 - accuracy: 0.5976 - val_loss: 0.8705 - val_accuracy: 0.5790\n",
      "Epoch 41/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.8361 - accuracy: 0.5966 - val_loss: 0.8808 - val_accuracy: 0.5695\n",
      "Epoch 42/100\n",
      "633/633 [==============================] - 55s 87ms/step - loss: 0.8317 - accuracy: 0.6007 - val_loss: 0.8674 - val_accuracy: 0.5815\n",
      "Epoch 43/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.8293 - accuracy: 0.6017 - val_loss: 0.8677 - val_accuracy: 0.5799\n",
      "Epoch 44/100\n",
      "633/633 [==============================] - 56s 89ms/step - loss: 0.8250 - accuracy: 0.6040 - val_loss: 0.8665 - val_accuracy: 0.5814\n",
      "Epoch 45/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.8203 - accuracy: 0.6064 - val_loss: 0.8707 - val_accuracy: 0.5835\n",
      "Epoch 46/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.8166 - accuracy: 0.6100 - val_loss: 0.8697 - val_accuracy: 0.5807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "633/633 [==============================] - 57s 89ms/step - loss: 0.8127 - accuracy: 0.6111 - val_loss: 0.8631 - val_accuracy: 0.5870\n",
      "Epoch 48/100\n",
      "633/633 [==============================] - 55s 87ms/step - loss: 0.8102 - accuracy: 0.6131 - val_loss: 0.8571 - val_accuracy: 0.5887\n",
      "Epoch 49/100\n",
      "633/633 [==============================] - 56s 89ms/step - loss: 0.8073 - accuracy: 0.6146 - val_loss: 0.8602 - val_accuracy: 0.5867\n",
      "Epoch 50/100\n",
      "633/633 [==============================] - 55s 87ms/step - loss: 0.8043 - accuracy: 0.6161 - val_loss: 0.8648 - val_accuracy: 0.5891\n",
      "Epoch 51/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.7994 - accuracy: 0.6198 - val_loss: 0.8677 - val_accuracy: 0.5846\n",
      "Epoch 52/100\n",
      "633/633 [==============================] - 54s 86ms/step - loss: 0.7963 - accuracy: 0.6207 - val_loss: 0.8603 - val_accuracy: 0.5911\n",
      "Epoch 53/100\n",
      "633/633 [==============================] - 56s 88ms/step - loss: 0.7937 - accuracy: 0.6221 - val_loss: 0.8553 - val_accuracy: 0.5914\n",
      "Epoch 54/100\n",
      "633/633 [==============================] - 53s 84ms/step - loss: 0.7905 - accuracy: 0.6244 - val_loss: 0.8570 - val_accuracy: 0.5897\n",
      "Epoch 55/100\n",
      "633/633 [==============================] - 55s 86ms/step - loss: 0.7861 - accuracy: 0.6269 - val_loss: 0.8501 - val_accuracy: 0.5951\n",
      "Epoch 56/100\n",
      "633/633 [==============================] - 52s 83ms/step - loss: 0.7831 - accuracy: 0.6287 - val_loss: 0.8596 - val_accuracy: 0.5865\n",
      "Epoch 57/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.7802 - accuracy: 0.6300 - val_loss: 0.8594 - val_accuracy: 0.5940\n",
      "Epoch 58/100\n",
      "633/633 [==============================] - 52s 83ms/step - loss: 0.7770 - accuracy: 0.6317 - val_loss: 0.8544 - val_accuracy: 0.5987\n",
      "Epoch 59/100\n",
      "633/633 [==============================] - 52s 83ms/step - loss: 0.7742 - accuracy: 0.6319 - val_loss: 0.8526 - val_accuracy: 0.6026\n",
      "Epoch 60/100\n",
      "633/633 [==============================] - 52s 83ms/step - loss: 0.7726 - accuracy: 0.6341 - val_loss: 0.8605 - val_accuracy: 0.5955\n",
      "Epoch 61/100\n",
      "633/633 [==============================] - 53s 84ms/step - loss: 0.7706 - accuracy: 0.6373 - val_loss: 0.8460 - val_accuracy: 0.6009\n",
      "Epoch 62/100\n",
      "633/633 [==============================] - 55s 87ms/step - loss: 0.7665 - accuracy: 0.6379 - val_loss: 0.8559 - val_accuracy: 0.5970\n",
      "Epoch 63/100\n",
      "633/633 [==============================] - 59s 93ms/step - loss: 0.7634 - accuracy: 0.6396 - val_loss: 0.8581 - val_accuracy: 0.5966\n",
      "Epoch 64/100\n",
      "633/633 [==============================] - 55s 86ms/step - loss: 0.7591 - accuracy: 0.6410 - val_loss: 0.8542 - val_accuracy: 0.6016\n",
      "Epoch 65/100\n",
      "633/633 [==============================] - 3146s 5s/step - loss: 0.7568 - accuracy: 0.6443 - val_loss: 0.8662 - val_accuracy: 0.5973\n",
      "Epoch 66/100\n",
      "633/633 [==============================] - 1970s 3s/step - loss: 0.7547 - accuracy: 0.6437 - val_loss: 0.8593 - val_accuracy: 0.6005\n",
      "Epoch 67/100\n",
      "633/633 [==============================] - 44s 69ms/step - loss: 0.7523 - accuracy: 0.6457 - val_loss: 0.8590 - val_accuracy: 0.6019\n",
      "Epoch 68/100\n",
      "633/633 [==============================] - 45s 71ms/step - loss: 0.7497 - accuracy: 0.6464 - val_loss: 0.8566 - val_accuracy: 0.6040\n",
      "Epoch 69/100\n",
      "633/633 [==============================] - 48s 76ms/step - loss: 0.7459 - accuracy: 0.6489 - val_loss: 0.8572 - val_accuracy: 0.5966\n",
      "Epoch 70/100\n",
      "633/633 [==============================] - 50s 78ms/step - loss: 0.7421 - accuracy: 0.6505 - val_loss: 0.8529 - val_accuracy: 0.6049\n",
      "Epoch 71/100\n",
      "633/633 [==============================] - 57s 90ms/step - loss: 0.7398 - accuracy: 0.6518 - val_loss: 0.8666 - val_accuracy: 0.6012\n",
      "Epoch 72/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.7387 - accuracy: 0.6552 - val_loss: 0.8559 - val_accuracy: 0.6073\n",
      "Epoch 73/100\n",
      "633/633 [==============================] - 48s 77ms/step - loss: 0.7374 - accuracy: 0.6538 - val_loss: 0.8624 - val_accuracy: 0.6067\n",
      "Epoch 74/100\n",
      "633/633 [==============================] - 50s 80ms/step - loss: 0.7322 - accuracy: 0.6564 - val_loss: 0.8627 - val_accuracy: 0.6063\n",
      "Epoch 75/100\n",
      "633/633 [==============================] - 60s 94ms/step - loss: 0.7312 - accuracy: 0.6574 - val_loss: 0.8621 - val_accuracy: 0.6113\n",
      "Epoch 76/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.7270 - accuracy: 0.6595 - val_loss: 0.8686 - val_accuracy: 0.6036\n",
      "Epoch 77/100\n",
      "633/633 [==============================] - 48s 75ms/step - loss: 0.7266 - accuracy: 0.6598 - val_loss: 0.8708 - val_accuracy: 0.6006\n",
      "Epoch 78/100\n",
      "633/633 [==============================] - 49s 77ms/step - loss: 0.7238 - accuracy: 0.6619 - val_loss: 0.8576 - val_accuracy: 0.6064\n",
      "Epoch 79/100\n",
      "633/633 [==============================] - 57s 91ms/step - loss: 0.7204 - accuracy: 0.6629 - val_loss: 0.8672 - val_accuracy: 0.6091\n",
      "Epoch 80/100\n",
      "633/633 [==============================] - 62s 99ms/step - loss: 0.7184 - accuracy: 0.6649 - val_loss: 0.8623 - val_accuracy: 0.6108\n",
      "Epoch 81/100\n",
      "633/633 [==============================] - 50s 78ms/step - loss: 0.7165 - accuracy: 0.6643 - val_loss: 0.8659 - val_accuracy: 0.6098\n",
      "Epoch 82/100\n",
      "633/633 [==============================] - 50s 79ms/step - loss: 0.7143 - accuracy: 0.6660 - val_loss: 0.8680 - val_accuracy: 0.6114\n",
      "Epoch 83/100\n",
      "633/633 [==============================] - 52s 82ms/step - loss: 0.7117 - accuracy: 0.6676 - val_loss: 0.8576 - val_accuracy: 0.6181\n",
      "Epoch 84/100\n",
      "633/633 [==============================] - 52s 82ms/step - loss: 0.7094 - accuracy: 0.6697 - val_loss: 0.8784 - val_accuracy: 0.6051\n",
      "Epoch 85/100\n",
      "633/633 [==============================] - 52s 82ms/step - loss: 0.7078 - accuracy: 0.6699 - val_loss: 0.8665 - val_accuracy: 0.6098\n",
      "Epoch 86/100\n",
      "633/633 [==============================] - 54s 85ms/step - loss: 0.7051 - accuracy: 0.6713 - val_loss: 0.8698 - val_accuracy: 0.6115\n",
      "Epoch 87/100\n",
      "633/633 [==============================] - 55s 88ms/step - loss: 0.7024 - accuracy: 0.6741 - val_loss: 0.8700 - val_accuracy: 0.6139\n",
      "Epoch 88/100\n",
      "633/633 [==============================] - 55s 88ms/step - loss: 0.6989 - accuracy: 0.6747 - val_loss: 0.8665 - val_accuracy: 0.6134\n",
      "Epoch 89/100\n",
      "633/633 [==============================] - 56s 89ms/step - loss: 0.6993 - accuracy: 0.6744 - val_loss: 0.8655 - val_accuracy: 0.6139\n",
      "Epoch 90/100\n",
      "633/633 [==============================] - 58s 91ms/step - loss: 0.6943 - accuracy: 0.6772 - val_loss: 0.8678 - val_accuracy: 0.6144\n",
      "Epoch 91/100\n",
      "633/633 [==============================] - 60s 95ms/step - loss: 0.6934 - accuracy: 0.6752 - val_loss: 0.8692 - val_accuracy: 0.6122\n",
      "Epoch 92/100\n",
      "633/633 [==============================] - 62s 98ms/step - loss: 0.6947 - accuracy: 0.6760 - val_loss: 0.8677 - val_accuracy: 0.6153\n",
      "Epoch 93/100\n",
      "633/633 [==============================] - 60s 95ms/step - loss: 0.6917 - accuracy: 0.6793 - val_loss: 0.8749 - val_accuracy: 0.6103\n",
      "Epoch 94/100\n",
      "633/633 [==============================] - 57s 91ms/step - loss: 0.6888 - accuracy: 0.6798 - val_loss: 0.8696 - val_accuracy: 0.6143\n",
      "Epoch 95/100\n",
      "633/633 [==============================] - 51s 81ms/step - loss: 0.6872 - accuracy: 0.6812 - val_loss: 0.8640 - val_accuracy: 0.6160\n",
      "Epoch 96/100\n",
      "633/633 [==============================] - 51s 80ms/step - loss: 0.6832 - accuracy: 0.6817 - val_loss: 0.8656 - val_accuracy: 0.6189\n",
      "Epoch 97/100\n",
      "633/633 [==============================] - 49s 77ms/step - loss: 0.6823 - accuracy: 0.6837 - val_loss: 0.8832 - val_accuracy: 0.6142\n",
      "Epoch 98/100\n",
      "633/633 [==============================] - 49s 77ms/step - loss: 0.6796 - accuracy: 0.6837 - val_loss: 0.8722 - val_accuracy: 0.6189\n",
      "Epoch 99/100\n",
      "633/633 [==============================] - 48s 76ms/step - loss: 0.6806 - accuracy: 0.6833 - val_loss: 0.8715 - val_accuracy: 0.6196\n",
      "Epoch 100/100\n",
      "633/633 [==============================] - 49s 77ms/step - loss: 0.6763 - accuracy: 0.6863 - val_loss: 0.8687 - val_accuracy: 0.6163\n",
      "<keras.callbacks.History object at 0x7f94f439b460>\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Thermal Preference Accuracy: 0.4017543859649123\n",
      "Thermal Preference Weighted F1 Score: 0.2783740976943023\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Preference Model\")\n",
    "thermalpref_model = define_model_architecture(num_classes=3)\n",
    "thermalpref_model, thermalpref_scaler = train_model(thermalpref_model, \n",
    "                                                    thermalpref_train, \n",
    "                                                    model_name='cnnlstm_lower_thermalpref_model', \n",
    "                                                    target_col='Thermal Preference', \n",
    "                                                    num_classes=3)\n",
    "\n",
    "thermalpref_eval = evaluate_model(thermalpref_model, \n",
    "                                  thermalpref_test, \n",
    "                                  thermalpref_scaler,\n",
    "                                  model_name='cnnlstm_lower_thermalpref_model', \n",
    "                                  target_col='Thermal Preference')\n",
    "print(\"Thermal Preference Accuracy:\", thermalpref_eval['accuracy'])\n",
    "print(\"Thermal Preference Weighted F1 Score:\", thermalpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Thermal Acceptability Model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,842\n",
      "Trainable params: 937,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "401/401 [==============================] - 33s 73ms/step - loss: 0.6905 - accuracy: 0.5314 - val_loss: 0.6884 - val_accuracy: 0.5429\n",
      "Epoch 2/100\n",
      "401/401 [==============================] - 30s 76ms/step - loss: 0.6874 - accuracy: 0.5425 - val_loss: 0.6803 - val_accuracy: 0.5508\n",
      "Epoch 3/100\n",
      "401/401 [==============================] - 31s 78ms/step - loss: 0.6766 - accuracy: 0.5561 - val_loss: 0.6683 - val_accuracy: 0.5615\n",
      "Epoch 4/100\n",
      "401/401 [==============================] - 31s 77ms/step - loss: 0.6744 - accuracy: 0.5581 - val_loss: 0.6662 - val_accuracy: 0.5645\n",
      "Epoch 5/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.6670 - accuracy: 0.5658 - val_loss: 0.6619 - val_accuracy: 0.5678\n",
      "Epoch 6/100\n",
      "401/401 [==============================] - 31s 76ms/step - loss: 0.6630 - accuracy: 0.5684 - val_loss: 0.6566 - val_accuracy: 0.5719\n",
      "Epoch 7/100\n",
      "401/401 [==============================] - 31s 77ms/step - loss: 0.6580 - accuracy: 0.5745 - val_loss: 0.6613 - val_accuracy: 0.5764\n",
      "Epoch 8/100\n",
      "401/401 [==============================] - 31s 76ms/step - loss: 0.6530 - accuracy: 0.5871 - val_loss: 0.6563 - val_accuracy: 0.5739\n",
      "Epoch 9/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.6476 - accuracy: 0.6005 - val_loss: 0.6362 - val_accuracy: 0.6171\n",
      "Epoch 10/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.6354 - accuracy: 0.6176 - val_loss: 0.6285 - val_accuracy: 0.6303\n",
      "Epoch 11/100\n",
      "401/401 [==============================] - 30s 76ms/step - loss: 0.6286 - accuracy: 0.6277 - val_loss: 0.6208 - val_accuracy: 0.6381\n",
      "Epoch 12/100\n",
      "401/401 [==============================] - 30s 76ms/step - loss: 0.6225 - accuracy: 0.6350 - val_loss: 0.6157 - val_accuracy: 0.6461\n",
      "Epoch 13/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.6182 - accuracy: 0.6385 - val_loss: 0.6114 - val_accuracy: 0.6455\n",
      "Epoch 14/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.6133 - accuracy: 0.6441 - val_loss: 0.6093 - val_accuracy: 0.6427\n",
      "Epoch 15/100\n",
      "401/401 [==============================] - 31s 76ms/step - loss: 0.6113 - accuracy: 0.6447 - val_loss: 0.6055 - val_accuracy: 0.6488\n",
      "Epoch 16/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.6057 - accuracy: 0.6525 - val_loss: 0.6005 - val_accuracy: 0.6509\n",
      "Epoch 17/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.6036 - accuracy: 0.6520 - val_loss: 0.6195 - val_accuracy: 0.6377\n",
      "Epoch 18/100\n",
      "401/401 [==============================] - 31s 77ms/step - loss: 0.6024 - accuracy: 0.6521 - val_loss: 0.5962 - val_accuracy: 0.6590\n",
      "Epoch 19/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5986 - accuracy: 0.6558 - val_loss: 0.5902 - val_accuracy: 0.6677\n",
      "Epoch 20/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5945 - accuracy: 0.6587 - val_loss: 0.5938 - val_accuracy: 0.6575\n",
      "Epoch 21/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.5923 - accuracy: 0.6623 - val_loss: 0.5882 - val_accuracy: 0.6641\n",
      "Epoch 22/100\n",
      "401/401 [==============================] - 30s 76ms/step - loss: 0.5907 - accuracy: 0.6637 - val_loss: 0.5830 - val_accuracy: 0.6674\n",
      "Epoch 23/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5895 - accuracy: 0.6635 - val_loss: 0.5902 - val_accuracy: 0.6644\n",
      "Epoch 24/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5849 - accuracy: 0.6668 - val_loss: 0.5765 - val_accuracy: 0.6740\n",
      "Epoch 25/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5818 - accuracy: 0.6707 - val_loss: 0.5744 - val_accuracy: 0.6761\n",
      "Epoch 26/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5810 - accuracy: 0.6712 - val_loss: 0.5770 - val_accuracy: 0.6777\n",
      "Epoch 27/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5775 - accuracy: 0.6745 - val_loss: 0.5744 - val_accuracy: 0.6768\n",
      "Epoch 28/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5755 - accuracy: 0.6761 - val_loss: 0.5751 - val_accuracy: 0.6769\n",
      "Epoch 29/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5733 - accuracy: 0.6783 - val_loss: 0.5774 - val_accuracy: 0.6746\n",
      "Epoch 30/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5705 - accuracy: 0.6794 - val_loss: 0.5705 - val_accuracy: 0.6793\n",
      "Epoch 31/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5686 - accuracy: 0.6820 - val_loss: 0.5673 - val_accuracy: 0.6795\n",
      "Epoch 32/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5670 - accuracy: 0.6822 - val_loss: 0.5689 - val_accuracy: 0.6853\n",
      "Epoch 33/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5654 - accuracy: 0.6836 - val_loss: 0.5670 - val_accuracy: 0.6828\n",
      "Epoch 34/100\n",
      "401/401 [==============================] - 31s 78ms/step - loss: 0.5626 - accuracy: 0.6877 - val_loss: 0.5623 - val_accuracy: 0.6862\n",
      "Epoch 35/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.5618 - accuracy: 0.6866 - val_loss: 0.5643 - val_accuracy: 0.6861\n",
      "Epoch 36/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5580 - accuracy: 0.6905 - val_loss: 0.5622 - val_accuracy: 0.6926\n",
      "Epoch 37/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.5576 - accuracy: 0.6912 - val_loss: 0.5720 - val_accuracy: 0.6810\n",
      "Epoch 38/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5559 - accuracy: 0.6928 - val_loss: 0.5615 - val_accuracy: 0.6867\n",
      "Epoch 39/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5535 - accuracy: 0.6929 - val_loss: 0.5573 - val_accuracy: 0.6891\n",
      "Epoch 40/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5513 - accuracy: 0.6939 - val_loss: 0.5619 - val_accuracy: 0.6860\n",
      "Epoch 41/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5481 - accuracy: 0.6989 - val_loss: 0.5579 - val_accuracy: 0.6901\n",
      "Epoch 42/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5494 - accuracy: 0.6960 - val_loss: 0.5589 - val_accuracy: 0.6892\n",
      "Epoch 43/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5449 - accuracy: 0.7022 - val_loss: 0.5709 - val_accuracy: 0.6824\n",
      "Epoch 44/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5431 - accuracy: 0.7013 - val_loss: 0.5539 - val_accuracy: 0.6924\n",
      "Epoch 45/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5429 - accuracy: 0.7006 - val_loss: 0.5513 - val_accuracy: 0.6966\n",
      "Epoch 46/100\n",
      "401/401 [==============================] - 29s 72ms/step - loss: 0.5402 - accuracy: 0.7042 - val_loss: 0.5539 - val_accuracy: 0.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5390 - accuracy: 0.7058 - val_loss: 0.5505 - val_accuracy: 0.6968\n",
      "Epoch 48/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5365 - accuracy: 0.7077 - val_loss: 0.5587 - val_accuracy: 0.6931\n",
      "Epoch 49/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5366 - accuracy: 0.7067 - val_loss: 0.5559 - val_accuracy: 0.6968\n",
      "Epoch 50/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5328 - accuracy: 0.7094 - val_loss: 0.5595 - val_accuracy: 0.6931\n",
      "Epoch 51/100\n",
      "401/401 [==============================] - 30s 75ms/step - loss: 0.5308 - accuracy: 0.7091 - val_loss: 0.5534 - val_accuracy: 0.6976\n",
      "Epoch 52/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5294 - accuracy: 0.7110 - val_loss: 0.5581 - val_accuracy: 0.6971\n",
      "Epoch 53/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5285 - accuracy: 0.7125 - val_loss: 0.5463 - val_accuracy: 0.7035\n",
      "Epoch 54/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5261 - accuracy: 0.7157 - val_loss: 0.5535 - val_accuracy: 0.6984\n",
      "Epoch 55/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5252 - accuracy: 0.7145 - val_loss: 0.5523 - val_accuracy: 0.6974\n",
      "Epoch 56/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5241 - accuracy: 0.7164 - val_loss: 0.5498 - val_accuracy: 0.7021\n",
      "Epoch 57/100\n",
      "401/401 [==============================] - 29s 72ms/step - loss: 0.5210 - accuracy: 0.7205 - val_loss: 0.5473 - val_accuracy: 0.7054\n",
      "Epoch 58/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5192 - accuracy: 0.7193 - val_loss: 0.5470 - val_accuracy: 0.7052\n",
      "Epoch 59/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5167 - accuracy: 0.7201 - val_loss: 0.5481 - val_accuracy: 0.7065\n",
      "Epoch 60/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5163 - accuracy: 0.7218 - val_loss: 0.5466 - val_accuracy: 0.7020\n",
      "Epoch 61/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5154 - accuracy: 0.7214 - val_loss: 0.5492 - val_accuracy: 0.7052\n",
      "Epoch 62/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5109 - accuracy: 0.7263 - val_loss: 0.5454 - val_accuracy: 0.7048\n",
      "Epoch 63/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5132 - accuracy: 0.7232 - val_loss: 0.5428 - val_accuracy: 0.7104\n",
      "Epoch 64/100\n",
      "401/401 [==============================] - 29s 72ms/step - loss: 0.5112 - accuracy: 0.7242 - val_loss: 0.5470 - val_accuracy: 0.7061\n",
      "Epoch 65/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5096 - accuracy: 0.7247 - val_loss: 0.5445 - val_accuracy: 0.7096\n",
      "Epoch 66/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5060 - accuracy: 0.7273 - val_loss: 0.5425 - val_accuracy: 0.7053\n",
      "Epoch 67/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.5030 - accuracy: 0.7300 - val_loss: 0.5528 - val_accuracy: 0.7034\n",
      "Epoch 68/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5048 - accuracy: 0.7291 - val_loss: 0.5489 - val_accuracy: 0.7070\n",
      "Epoch 69/100\n",
      "401/401 [==============================] - 29s 72ms/step - loss: 0.5014 - accuracy: 0.7322 - val_loss: 0.5490 - val_accuracy: 0.7029\n",
      "Epoch 70/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5015 - accuracy: 0.7310 - val_loss: 0.5480 - val_accuracy: 0.7083\n",
      "Epoch 71/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.5019 - accuracy: 0.7315 - val_loss: 0.5434 - val_accuracy: 0.7091\n",
      "Epoch 72/100\n",
      "401/401 [==============================] - 29s 72ms/step - loss: 0.4989 - accuracy: 0.7325 - val_loss: 0.5458 - val_accuracy: 0.7092\n",
      "Epoch 73/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4983 - accuracy: 0.7320 - val_loss: 0.5505 - val_accuracy: 0.7043\n",
      "Epoch 74/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4959 - accuracy: 0.7349 - val_loss: 0.5507 - val_accuracy: 0.7024\n",
      "Epoch 75/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4940 - accuracy: 0.7360 - val_loss: 0.5415 - val_accuracy: 0.7126\n",
      "Epoch 76/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4929 - accuracy: 0.7364 - val_loss: 0.5429 - val_accuracy: 0.7069\n",
      "Epoch 77/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4926 - accuracy: 0.7382 - val_loss: 0.5473 - val_accuracy: 0.7095\n",
      "Epoch 78/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4909 - accuracy: 0.7406 - val_loss: 0.5475 - val_accuracy: 0.7125\n",
      "Epoch 79/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4893 - accuracy: 0.7396 - val_loss: 0.5392 - val_accuracy: 0.7190\n",
      "Epoch 80/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4887 - accuracy: 0.7383 - val_loss: 0.5471 - val_accuracy: 0.7062\n",
      "Epoch 81/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4870 - accuracy: 0.7414 - val_loss: 0.5490 - val_accuracy: 0.7087\n",
      "Epoch 82/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4887 - accuracy: 0.7418 - val_loss: 0.5415 - val_accuracy: 0.7113\n",
      "Epoch 83/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4825 - accuracy: 0.7450 - val_loss: 0.5530 - val_accuracy: 0.7080\n",
      "Epoch 84/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4838 - accuracy: 0.7433 - val_loss: 0.5476 - val_accuracy: 0.7138\n",
      "Epoch 85/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4838 - accuracy: 0.7432 - val_loss: 0.5470 - val_accuracy: 0.7137\n",
      "Epoch 86/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4813 - accuracy: 0.7452 - val_loss: 0.5499 - val_accuracy: 0.7119\n",
      "Epoch 87/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4782 - accuracy: 0.7478 - val_loss: 0.5528 - val_accuracy: 0.7125\n",
      "Epoch 88/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4795 - accuracy: 0.7464 - val_loss: 0.5434 - val_accuracy: 0.7167\n",
      "Epoch 89/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4770 - accuracy: 0.7488 - val_loss: 0.5475 - val_accuracy: 0.7163\n",
      "Epoch 90/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4741 - accuracy: 0.7499 - val_loss: 0.5435 - val_accuracy: 0.7169\n",
      "Epoch 91/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4744 - accuracy: 0.7504 - val_loss: 0.5446 - val_accuracy: 0.7190\n",
      "Epoch 92/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4734 - accuracy: 0.7532 - val_loss: 0.5456 - val_accuracy: 0.7180\n",
      "Epoch 93/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4724 - accuracy: 0.7509 - val_loss: 0.5456 - val_accuracy: 0.7167\n",
      "Epoch 94/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4709 - accuracy: 0.7543 - val_loss: 0.5461 - val_accuracy: 0.7212\n",
      "Epoch 95/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4717 - accuracy: 0.7497 - val_loss: 0.5506 - val_accuracy: 0.7144\n",
      "Epoch 96/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4684 - accuracy: 0.7527 - val_loss: 0.5478 - val_accuracy: 0.7190\n",
      "Epoch 97/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4684 - accuracy: 0.7552 - val_loss: 0.5478 - val_accuracy: 0.7174\n",
      "Epoch 98/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4676 - accuracy: 0.7548 - val_loss: 0.5440 - val_accuracy: 0.7225\n",
      "Epoch 99/100\n",
      "401/401 [==============================] - 29s 73ms/step - loss: 0.4672 - accuracy: 0.7556 - val_loss: 0.5582 - val_accuracy: 0.7090\n",
      "Epoch 100/100\n",
      "401/401 [==============================] - 30s 74ms/step - loss: 0.4647 - accuracy: 0.7567 - val_loss: 0.5484 - val_accuracy: 0.7180\n",
      "<keras.callbacks.History object at 0x7f94e3626a30>\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Thermal Acceptability Accuracy: 0.23333333333333334\n",
      "Thermal Acceptability Weighted F1 Score: 0.18347248983087133\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate thermal acceptability model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Thermal Acceptability Model\")\n",
    "thermalacc_model = define_model_architecture(num_classes=2)\n",
    "thermalacc_model, thermalacc_scaler = train_model(thermalacc_model, \n",
    "                                                  thermalacc_train, \n",
    "                                                  model_name='cnnlstm_lower_thermalacc_model', \n",
    "                                                  target_col='Thermal Acceptability', \n",
    "                                                  num_classes=2)\n",
    "\n",
    "thermalacc_eval = evaluate_model(thermalacc_model, \n",
    "                                 thermalacc_test, \n",
    "                                 thermalacc_scaler,\n",
    "                                 model_name='cnnlstm_lower_thermalacc_model', \n",
    "                                 target_col='Thermal Acceptability')\n",
    "print(\"Thermal Acceptability Accuracy:\", thermalacc_eval['accuracy'])\n",
    "print(\"Thermal Acceptability Weighted F1 Score:\", thermalacc_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Air Movement Preference Model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7, 128)            768       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 7, 256)            394240    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,859\n",
      "Trainable params: 937,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "261/261 [==============================] - 23s 71ms/step - loss: 1.0700 - accuracy: 0.4118 - val_loss: 1.0490 - val_accuracy: 0.4345\n",
      "Epoch 2/100\n",
      "261/261 [==============================] - 18s 71ms/step - loss: 1.0465 - accuracy: 0.4518 - val_loss: 1.0320 - val_accuracy: 0.4593\n",
      "Epoch 3/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 1.0276 - accuracy: 0.4696 - val_loss: 1.0289 - val_accuracy: 0.4695\n",
      "Epoch 4/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 1.0153 - accuracy: 0.4834 - val_loss: 1.0041 - val_accuracy: 0.4890\n",
      "Epoch 5/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 1.0039 - accuracy: 0.4880 - val_loss: 0.9926 - val_accuracy: 0.5003\n",
      "Epoch 6/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9963 - accuracy: 0.4984 - val_loss: 0.9904 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9852 - accuracy: 0.5039 - val_loss: 0.9749 - val_accuracy: 0.5144\n",
      "Epoch 8/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9753 - accuracy: 0.5133 - val_loss: 0.9837 - val_accuracy: 0.4993\n",
      "Epoch 9/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.9658 - accuracy: 0.5222 - val_loss: 0.9753 - val_accuracy: 0.5119\n",
      "Epoch 10/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.9576 - accuracy: 0.5277 - val_loss: 0.9473 - val_accuracy: 0.5270\n",
      "Epoch 11/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9493 - accuracy: 0.5315 - val_loss: 0.9464 - val_accuracy: 0.5313\n",
      "Epoch 12/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9407 - accuracy: 0.5366 - val_loss: 0.9479 - val_accuracy: 0.5243\n",
      "Epoch 13/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9362 - accuracy: 0.5399 - val_loss: 0.9319 - val_accuracy: 0.5424\n",
      "Epoch 14/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.9295 - accuracy: 0.5465 - val_loss: 0.9378 - val_accuracy: 0.5436\n",
      "Epoch 15/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9220 - accuracy: 0.5513 - val_loss: 0.9207 - val_accuracy: 0.5521\n",
      "Epoch 16/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9117 - accuracy: 0.5599 - val_loss: 0.9146 - val_accuracy: 0.5537\n",
      "Epoch 17/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.9041 - accuracy: 0.5632 - val_loss: 0.9108 - val_accuracy: 0.5537\n",
      "Epoch 18/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.8969 - accuracy: 0.5689 - val_loss: 0.9070 - val_accuracy: 0.5587\n",
      "Epoch 19/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.8873 - accuracy: 0.5756 - val_loss: 0.9013 - val_accuracy: 0.5670\n",
      "Epoch 20/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8801 - accuracy: 0.5791 - val_loss: 0.8823 - val_accuracy: 0.5750\n",
      "Epoch 21/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8712 - accuracy: 0.5807 - val_loss: 0.8790 - val_accuracy: 0.5720\n",
      "Epoch 22/100\n",
      "261/261 [==============================] - 18s 71ms/step - loss: 0.8600 - accuracy: 0.5899 - val_loss: 0.8672 - val_accuracy: 0.5783\n",
      "Epoch 23/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8557 - accuracy: 0.5918 - val_loss: 0.8626 - val_accuracy: 0.5824\n",
      "Epoch 24/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8470 - accuracy: 0.5957 - val_loss: 0.8543 - val_accuracy: 0.5898\n",
      "Epoch 25/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8369 - accuracy: 0.6046 - val_loss: 0.8500 - val_accuracy: 0.5928\n",
      "Epoch 26/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8269 - accuracy: 0.6086 - val_loss: 0.8443 - val_accuracy: 0.5999\n",
      "Epoch 27/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.8209 - accuracy: 0.6146 - val_loss: 0.8372 - val_accuracy: 0.5964\n",
      "Epoch 28/100\n",
      "261/261 [==============================] - 18s 70ms/step - loss: 0.8106 - accuracy: 0.6142 - val_loss: 0.8282 - val_accuracy: 0.6036\n",
      "Epoch 29/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.8017 - accuracy: 0.6232 - val_loss: 0.8266 - val_accuracy: 0.6056\n",
      "Epoch 30/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7966 - accuracy: 0.6263 - val_loss: 0.8168 - val_accuracy: 0.6144\n",
      "Epoch 31/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7871 - accuracy: 0.6310 - val_loss: 0.8158 - val_accuracy: 0.6128\n",
      "Epoch 32/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7810 - accuracy: 0.6349 - val_loss: 0.8165 - val_accuracy: 0.6133\n",
      "Epoch 33/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.7724 - accuracy: 0.6368 - val_loss: 0.7983 - val_accuracy: 0.6212\n",
      "Epoch 34/100\n",
      "261/261 [==============================] - 18s 71ms/step - loss: 0.7623 - accuracy: 0.6442 - val_loss: 0.8087 - val_accuracy: 0.6176\n",
      "Epoch 35/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7583 - accuracy: 0.6444 - val_loss: 0.7942 - val_accuracy: 0.6248\n",
      "Epoch 36/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7483 - accuracy: 0.6488 - val_loss: 0.8110 - val_accuracy: 0.6149\n",
      "Epoch 37/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7445 - accuracy: 0.6537 - val_loss: 0.8064 - val_accuracy: 0.6156\n",
      "Epoch 38/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7363 - accuracy: 0.6578 - val_loss: 0.7837 - val_accuracy: 0.6350\n",
      "Epoch 39/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.7275 - accuracy: 0.6600 - val_loss: 0.7751 - val_accuracy: 0.6391\n",
      "Epoch 40/100\n",
      "261/261 [==============================] - 18s 71ms/step - loss: 0.7277 - accuracy: 0.6610 - val_loss: 0.7805 - val_accuracy: 0.6354\n",
      "Epoch 41/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.7192 - accuracy: 0.6670 - val_loss: 0.7752 - val_accuracy: 0.6441\n",
      "Epoch 42/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7138 - accuracy: 0.6677 - val_loss: 0.7819 - val_accuracy: 0.6428\n",
      "Epoch 43/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7082 - accuracy: 0.6727 - val_loss: 0.7689 - val_accuracy: 0.6441\n",
      "Epoch 44/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.7021 - accuracy: 0.6748 - val_loss: 0.7788 - val_accuracy: 0.6415\n",
      "Epoch 45/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6938 - accuracy: 0.6777 - val_loss: 0.7649 - val_accuracy: 0.6459\n",
      "Epoch 46/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.6885 - accuracy: 0.6816 - val_loss: 0.7683 - val_accuracy: 0.6424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6845 - accuracy: 0.6826 - val_loss: 0.7697 - val_accuracy: 0.6441\n",
      "Epoch 48/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6838 - accuracy: 0.6865 - val_loss: 0.7562 - val_accuracy: 0.6477\n",
      "Epoch 49/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6729 - accuracy: 0.6912 - val_loss: 0.7518 - val_accuracy: 0.6551\n",
      "Epoch 50/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6736 - accuracy: 0.6889 - val_loss: 0.7638 - val_accuracy: 0.6463\n",
      "Epoch 51/100\n",
      "261/261 [==============================] - 18s 71ms/step - loss: 0.6676 - accuracy: 0.6915 - val_loss: 0.7528 - val_accuracy: 0.6503\n",
      "Epoch 52/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6626 - accuracy: 0.6943 - val_loss: 0.7579 - val_accuracy: 0.6569\n",
      "Epoch 53/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6573 - accuracy: 0.6991 - val_loss: 0.7675 - val_accuracy: 0.6508\n",
      "Epoch 54/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6574 - accuracy: 0.6964 - val_loss: 0.7584 - val_accuracy: 0.6567\n",
      "Epoch 55/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6500 - accuracy: 0.7025 - val_loss: 0.7710 - val_accuracy: 0.6546\n",
      "Epoch 56/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6419 - accuracy: 0.7039 - val_loss: 0.7669 - val_accuracy: 0.6546\n",
      "Epoch 57/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.6410 - accuracy: 0.7020 - val_loss: 0.7475 - val_accuracy: 0.6593\n",
      "Epoch 58/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6342 - accuracy: 0.7107 - val_loss: 0.7393 - val_accuracy: 0.6695\n",
      "Epoch 59/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6351 - accuracy: 0.7070 - val_loss: 0.7377 - val_accuracy: 0.6655\n",
      "Epoch 60/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6254 - accuracy: 0.7164 - val_loss: 0.7556 - val_accuracy: 0.6614\n",
      "Epoch 61/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6277 - accuracy: 0.7128 - val_loss: 0.7403 - val_accuracy: 0.6654\n",
      "Epoch 62/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6199 - accuracy: 0.7156 - val_loss: 0.7355 - val_accuracy: 0.6717\n",
      "Epoch 63/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6147 - accuracy: 0.7181 - val_loss: 0.7492 - val_accuracy: 0.6654\n",
      "Epoch 64/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6138 - accuracy: 0.7199 - val_loss: 0.7716 - val_accuracy: 0.6548\n",
      "Epoch 65/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6124 - accuracy: 0.7178 - val_loss: 0.7566 - val_accuracy: 0.6684\n",
      "Epoch 66/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.6035 - accuracy: 0.7267 - val_loss: 0.7495 - val_accuracy: 0.6659\n",
      "Epoch 67/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.6041 - accuracy: 0.7253 - val_loss: 0.7581 - val_accuracy: 0.6677\n",
      "Epoch 68/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.6060 - accuracy: 0.7239 - val_loss: 0.7482 - val_accuracy: 0.6717\n",
      "Epoch 69/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5959 - accuracy: 0.7273 - val_loss: 0.7432 - val_accuracy: 0.6768\n",
      "Epoch 70/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5938 - accuracy: 0.7289 - val_loss: 0.7529 - val_accuracy: 0.6647\n",
      "Epoch 71/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.5933 - accuracy: 0.7302 - val_loss: 0.7458 - val_accuracy: 0.6725\n",
      "Epoch 72/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.5819 - accuracy: 0.7360 - val_loss: 0.7632 - val_accuracy: 0.6660\n",
      "Epoch 73/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5823 - accuracy: 0.7353 - val_loss: 0.7508 - val_accuracy: 0.6787\n",
      "Epoch 74/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5741 - accuracy: 0.7370 - val_loss: 0.7658 - val_accuracy: 0.6666\n",
      "Epoch 75/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5763 - accuracy: 0.7375 - val_loss: 0.7476 - val_accuracy: 0.6766\n",
      "Epoch 76/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.5713 - accuracy: 0.7392 - val_loss: 0.7762 - val_accuracy: 0.6624\n",
      "Epoch 77/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.5725 - accuracy: 0.7406 - val_loss: 0.7570 - val_accuracy: 0.6786\n",
      "Epoch 78/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.5686 - accuracy: 0.7395 - val_loss: 0.7610 - val_accuracy: 0.6702\n",
      "Epoch 79/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5691 - accuracy: 0.7423 - val_loss: 0.7614 - val_accuracy: 0.6765\n",
      "Epoch 80/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5597 - accuracy: 0.7444 - val_loss: 0.7678 - val_accuracy: 0.6743\n",
      "Epoch 81/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.5595 - accuracy: 0.7438 - val_loss: 0.7477 - val_accuracy: 0.6835\n",
      "Epoch 82/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5556 - accuracy: 0.7471 - val_loss: 0.7456 - val_accuracy: 0.6790\n",
      "Epoch 83/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5561 - accuracy: 0.7471 - val_loss: 0.7629 - val_accuracy: 0.6738\n",
      "Epoch 84/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5619 - accuracy: 0.7452 - val_loss: 0.7557 - val_accuracy: 0.6773\n",
      "Epoch 85/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.5486 - accuracy: 0.7521 - val_loss: 0.7788 - val_accuracy: 0.6690\n",
      "Epoch 86/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5449 - accuracy: 0.7547 - val_loss: 0.7622 - val_accuracy: 0.6858\n",
      "Epoch 87/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5487 - accuracy: 0.7534 - val_loss: 0.7634 - val_accuracy: 0.6762\n",
      "Epoch 88/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.5457 - accuracy: 0.7557 - val_loss: 0.7657 - val_accuracy: 0.6809\n",
      "Epoch 89/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5384 - accuracy: 0.7550 - val_loss: 0.7504 - val_accuracy: 0.6814\n",
      "Epoch 90/100\n",
      "261/261 [==============================] - 19s 72ms/step - loss: 0.5397 - accuracy: 0.7547 - val_loss: 0.7485 - val_accuracy: 0.6896\n",
      "Epoch 91/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5296 - accuracy: 0.7626 - val_loss: 0.7541 - val_accuracy: 0.6824\n",
      "Epoch 92/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.5305 - accuracy: 0.7587 - val_loss: 0.7745 - val_accuracy: 0.6804\n",
      "Epoch 93/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5272 - accuracy: 0.7617 - val_loss: 0.7716 - val_accuracy: 0.6817\n",
      "Epoch 94/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.5317 - accuracy: 0.7606 - val_loss: 0.7670 - val_accuracy: 0.6896\n",
      "Epoch 95/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.5265 - accuracy: 0.7608 - val_loss: 0.7713 - val_accuracy: 0.6822\n",
      "Epoch 96/100\n",
      "261/261 [==============================] - 19s 74ms/step - loss: 0.5288 - accuracy: 0.7587 - val_loss: 0.7651 - val_accuracy: 0.6820\n",
      "Epoch 97/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5281 - accuracy: 0.7612 - val_loss: 0.7669 - val_accuracy: 0.6854\n",
      "Epoch 98/100\n",
      "261/261 [==============================] - 19s 71ms/step - loss: 0.5183 - accuracy: 0.7657 - val_loss: 0.7709 - val_accuracy: 0.6866\n",
      "Epoch 99/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5099 - accuracy: 0.7697 - val_loss: 0.8036 - val_accuracy: 0.6726\n",
      "Epoch 100/100\n",
      "261/261 [==============================] - 19s 73ms/step - loss: 0.5116 - accuracy: 0.7673 - val_loss: 0.7756 - val_accuracy: 0.6820\n",
      "<keras.callbacks.History object at 0x7f94e3557460>\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Air Movement Preference Accuracy: 0.531578947368421\n",
      "Air Movement Preference Weighted F1 Score: 0.49405510370221006\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate air movement preference model (source: ASHRAE, target: BCA)\n",
    "print(\"Training Air Movement Preference Model\")\n",
    "airpref_model = define_model_architecture(num_classes=3)\n",
    "airpref_model, airpref_scaler = train_model(airpref_model, \n",
    "                                            airpref_train, \n",
    "                                            model_name='cnnlstm_lower_airpref_model', \n",
    "                                            target_col='Air Movement Preference', \n",
    "                                            num_classes=3)\n",
    "\n",
    "airpref_eval = evaluate_model(airpref_model, \n",
    "                              airpref_test, \n",
    "                              airpref_scaler,\n",
    "                              model_name='cnnlstm_lower_airpref_model', \n",
    "                              target_col='Air Movement Preference')\n",
    "print(\"Air Movement Preference Accuracy:\", airpref_eval['accuracy'])\n",
    "print(\"Air Movement Preference Weighted F1 Score:\", airpref_eval['weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
